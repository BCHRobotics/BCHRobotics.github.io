{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"beans","title":"Home"},{"location":"rationale/","text":"The Rationale: The How and Why of Our Robot Code So our robot code has gotten a top-to-bottom revamp, and hopefully a lot of the code that we're using now gets used in years to come. \"The Rationale\" is a little blog-thing that aims to explain how our code works and why it works that way, for future team members or people from other teams to read. Basically the idea is, if you ever end up asking \"how do I ___?\" or \"why is this code like this?\" then you can just look it up here. Most of this is written by Maximilian McDiarmid, aka. 10tothe6 , you can reach him at fullautorobots@gmail.com if you want to ask anything. Directory: Gamepiece Detection Autos Managing Mechanisms Dashboard Pathfinding Apriltags","title":"The Rationale: The How and Why of Our Robot Code"},{"location":"rationale/#the-rationale-the-how-and-why-of-our-robot-code","text":"So our robot code has gotten a top-to-bottom revamp, and hopefully a lot of the code that we're using now gets used in years to come. \"The Rationale\" is a little blog-thing that aims to explain how our code works and why it works that way, for future team members or people from other teams to read. Basically the idea is, if you ever end up asking \"how do I ___?\" or \"why is this code like this?\" then you can just look it up here. Most of this is written by Maximilian McDiarmid, aka. 10tothe6 , you can reach him at fullautorobots@gmail.com if you want to ask anything.","title":"The Rationale: The How and Why of Our Robot Code"},{"location":"rationale/#directory","text":"Gamepiece Detection Autos Managing Mechanisms Dashboard Pathfinding Apriltags","title":"Directory:"},{"location":"rationale_dashboard/","text":"The Rationale Behind: Our FRC Dashboard (Drivetools) by 10tothe6 There are a lot of programs that run on driverstations that can display information from the robot to anyone who happens to be driving it. We all know them as dashboards . Here are the most popular ones, from what I've seen: WPILib Shuffleboard WPILib SmartDashboard LabVIEW Glass AdvantageScope Elastic As you can see, there are a few to choose from (to be fair, not all of these are the kinds of dashboards you would use during a match , some are more suited for testing in-house). Which one did we pick? Well, we didn't. The dashboard that our team uses is called Drivetools , and it's developed by FAR Robotics (that's a fancy way of saying that it's developed by me, 10tothe6 ). So add that one to the list, I guess. Alright so why did I decide to make my own dashboard? First let's look at what I dislike about the existing dashboards. (I admit that I'm not the most well-informed, feel free to let me know that I'm wrong about some of these) LabView : It's... old. And not very easy to work with, from what I've seen. Shuffleboard : It's just not as customizable as I'd like. SmartDashboard : I've never seen it not glitch out, and display the text weirdly. Also old. Glass : Actually I can't think of anything, I guess it's a little busy. AdvantageScope : Never tried it, but I know it doesn't work that well for competition scenarios. Elastic : Best one that I've seen, I don't have any gripes about it. Obviously that's not enough, I mean why not just use Elastic ? The big reason is that as a part of FAR Robotics I want to do a lot of more advanced things that involve communication from the computer to the robot. It's really useful to have a custom solution for that, which is why we didn't use some other teams custom dashboard. In the end, it comes down to features. There are a few really specific features that none of the other dashboards have, that Drivetools does. And hey, it's a good opportunity to try and improve on things, right? (I encourage you to try Drivetools by the way, I think its cool)","title":"The Rationale Behind: Our FRC Dashboard (Drivetools)"},{"location":"rationale_dashboard/#the-rationale-behind-our-frc-dashboard-drivetools","text":"by 10tothe6 There are a lot of programs that run on driverstations that can display information from the robot to anyone who happens to be driving it. We all know them as dashboards . Here are the most popular ones, from what I've seen: WPILib Shuffleboard WPILib SmartDashboard LabVIEW Glass AdvantageScope Elastic As you can see, there are a few to choose from (to be fair, not all of these are the kinds of dashboards you would use during a match , some are more suited for testing in-house). Which one did we pick? Well, we didn't. The dashboard that our team uses is called Drivetools , and it's developed by FAR Robotics (that's a fancy way of saying that it's developed by me, 10tothe6 ). So add that one to the list, I guess. Alright so why did I decide to make my own dashboard? First let's look at what I dislike about the existing dashboards. (I admit that I'm not the most well-informed, feel free to let me know that I'm wrong about some of these) LabView : It's... old. And not very easy to work with, from what I've seen. Shuffleboard : It's just not as customizable as I'd like. SmartDashboard : I've never seen it not glitch out, and display the text weirdly. Also old. Glass : Actually I can't think of anything, I guess it's a little busy. AdvantageScope : Never tried it, but I know it doesn't work that well for competition scenarios. Elastic : Best one that I've seen, I don't have any gripes about it. Obviously that's not enough, I mean why not just use Elastic ? The big reason is that as a part of FAR Robotics I want to do a lot of more advanced things that involve communication from the computer to the robot. It's really useful to have a custom solution for that, which is why we didn't use some other teams custom dashboard. In the end, it comes down to features. There are a few really specific features that none of the other dashboards have, that Drivetools does. And hey, it's a good opportunity to try and improve on things, right? (I encourage you to try Drivetools by the way, I think its cool)","title":"The Rationale Behind: Our FRC Dashboard (Drivetools)"},{"location":"rationale_detection/","text":"The Rationale Behind: Gamepiece Detection by 10tothe6 Something we need for a long-term software solution is a way of seeing game pieces on the field. There are two ways to do this: * you process the image and use thresholds to look for groups of color (from now on referred to as thresholding ) * you use a neural network (from now on referred to as machine learning ) For 2024 Crescendo we used thresholding , and it was difficult to adjust the thresholds to different lighting settings. It was also very possible that the camera might pick up on things that aren\u2019t game pieces. This wasn\u2019t that bad with the very-orange notes, but gets worse when the game piece is a neutral color (e.g. white), like coral in 2025 Reefscape. It\u2019s even worse when the game pieces are red and blue, like in 2022 Rapid React, because so many other game elements are the same colors. Overall this approach is sketchy at best, and for some game pieces is practically impossible. Not a good long term solution. Machine learning is much better. It allows for reliable detection of practically any game piece, if you train the neural network well enough. It is much less affected by neural-colored pieces, and red-and-blue pieces. Is it harder to get going? Yes. But from my experience programmers on our team often have little to do, and the process of training a model can be done by less-experienced students.","title":"The Rationale Behind: Gamepiece Detection"},{"location":"rationale_detection/#the-rationale-behind-gamepiece-detection","text":"by 10tothe6 Something we need for a long-term software solution is a way of seeing game pieces on the field. There are two ways to do this: * you process the image and use thresholds to look for groups of color (from now on referred to as thresholding ) * you use a neural network (from now on referred to as machine learning ) For 2024 Crescendo we used thresholding , and it was difficult to adjust the thresholds to different lighting settings. It was also very possible that the camera might pick up on things that aren\u2019t game pieces. This wasn\u2019t that bad with the very-orange notes, but gets worse when the game piece is a neutral color (e.g. white), like coral in 2025 Reefscape. It\u2019s even worse when the game pieces are red and blue, like in 2022 Rapid React, because so many other game elements are the same colors. Overall this approach is sketchy at best, and for some game pieces is practically impossible. Not a good long term solution. Machine learning is much better. It allows for reliable detection of practically any game piece, if you train the neural network well enough. It is much less affected by neural-colored pieces, and red-and-blue pieces. Is it harder to get going? Yes. But from my experience programmers on our team often have little to do, and the process of training a model can be done by less-experienced students.","title":"The Rationale Behind: Gamepiece Detection"}]}